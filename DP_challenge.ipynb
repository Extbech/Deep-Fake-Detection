{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Fake Detection Challenge"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from keras import layers\n",
    "from keras.utils.np_utils  import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "# import visualkeras\n",
    "\n",
    "import cv2\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from model2D import *\n",
    "from model3D_small import *\n",
    "from Imports.visualize import *\n",
    "from Imports.extraction import *\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_videoes = \"data/train_sample_videos\"\n",
    "test_videos = \"data/test_videos\"\n",
    "\n",
    "print(f\"Train Videoes: {len(os.listdir(train_videoes))}\\nTest Vidoes: {len(os.listdir(test_videos))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.read_json(train_videoes+\"/metadata.json\").T\n",
    "labels_col = meta_data[\"label\"].to_list()\n",
    "paths_col = meta_data.index.to_list()\n",
    "\n",
    "print(meta_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count_series = meta_data[\"label\"].value_counts()\n",
    "fake_count = label_count_series[\"FAKE\"]\n",
    "real_count = label_count_series[\"REAL\"]\n",
    "\n",
    "visualize_real_vs_fake([real_count, fake_count])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite skewed dataset. Might want to consider upsampling of real classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_videos_sample = os.listdir(train_videoes)\n",
    "sample_file_names = training_videos_sample.copy()\n",
    "complete_paths = []\n",
    "\n",
    "for path in paths_col:\n",
    "    complete_paths.append(train_videoes+\"/\"+path)\n",
    "    \n",
    "complete_paths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(faces, indices) = get_faces(complete_paths, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_face_features(faces, indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 'imagenet'\n",
    "include_top = False\n",
    "pooling = 'avg'\n",
    "\n",
    "model = ResNet50(weights, include_top, pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = complete_paths\n",
    "frames_each_video = 5 \n",
    "video_amount = 200\n",
    "\n",
    "video_array_colors, face_regions = get_frames_v2(paths, frames_each_video, video_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_features = extract_features(face_regions, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vid_arr_col.shape)\n",
    "print(vid_arr_col[8].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0 if val!=\"FAKE\" else 1 for val in labels_col ]\n",
    "y =np.array(y)\n",
    "np.delete(y, indices)\n",
    "y = to_categorical(y, num_classes=None).astype(int)\n",
    "y[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_features, face_regions = extract_features_v2(vid_arr_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42,perplexity=20)\n",
    "tsne_results = tsne.fit_transform(video_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = visualkeras.layered_view(test_m, to_file=\"images/layers_yo.png\", legend=True)\n",
    "vis.show()\n",
    "plt.rcParams.update({'font.size':500})  # set the legend font size to 56\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(test_m, to_file=\"images/layerv2.png\", show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne_with_images(tsne_results, face_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate some example data\n",
    "data = np.random.rand(10, 10)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create the heatmap\n",
    "heatmap = ax.imshow(data, cmap='viridis')\n",
    "\n",
    "# Create the colorbar\n",
    "cbar = fig.colorbar(heatmap, ax=ax)\n",
    "\n",
    "# Change the font size of the colorbar labels\n",
    "cbar.ax.tick_params(labelsize=14)  # You can set the desired font size here\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_faces(face_regions, figsize=(10, 10), width=5, height=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_video(faces[2], (30,5), 2, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tSNE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILD MODEL\n",
    "- Add Layers\n",
    "- Add Loss function, optimizers, and metrics\n",
    "- Compile model and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_class = compute_class_weight(class_weight='balanced',classes=[0,1],y=np.argmax(y, axis=1))\n",
    "class_weights = dict(zip(np.unique(y), weight_class))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_3D_model(input_data):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(layers.Conv3D(filters=64, kernel_size=3, padding=\"same\", strides=1, activation=\"relu\", input_shape=input_data.shape[1:]))\n",
    "    model.add(layers.MaxPool3D(pool_size=2, padding=\"same\"))\n",
    "    model.add(layers.Conv3D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(layers.MaxPool3D(pool_size=2, padding=\"same\"))\n",
    "    model.add(layers.Conv3D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(layers.MaxPool3D(pool_size=2, padding=\"same\"))\n",
    "    model.add(layers.Conv3D(filters=8, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(layers.MaxPool3D(pool_size=2, padding=\"same\"))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(layers.Dense(2 ,activation=\"softmax\"))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(input_data):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(layers.Conv3D(filters=32, kernel_size=(2,2,2),input_shape=input_data.shape[1:],\n",
    "                activation='relu',\n",
    "                padding='same', data_format='channels_last'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ConvLSTM2D(filters=16, kernel_size=(2, 2),\n",
    "                    padding='same', return_sequences=True))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "    model.add(layers.ConvLSTM2D(filters=16, kernel_size=(2, 2),\n",
    "                    padding='same', return_sequences=True))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.MaxPooling3D(pool_size=(2,2,2)))\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dense(32,activation='elu'))\n",
    "\n",
    "    model.add(layers.Dense(2,activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_m = test_model(faces)\n",
    "test_m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = \"binary_crossentropy\"\n",
    "optimizer = \"adam\"\n",
    "metrics=[\"accuracy\"]\n",
    "test_m.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_test = test_m.fit(faces, \n",
    "                          y[:faces.shape[0]],\n",
    "                          epochs=10, \n",
    "                          batch_size=10, \n",
    "                          verbose=1, \n",
    "                          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = test_m.predict(vid_arr_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_y = np.argmax(y[:vid_arr_col.shape[0]], axis=1)\n",
    "pred_y = np.argmax(pred_y, axis=1)\n",
    "print(classification_report(actual_y, pred_y, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfm = confusion_matrix(actual_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cfm, display_labels= [\"REAL\", \"FAKE\"])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3D_col = build_3D_model(vid_arr_col)\n",
    "model_3D_col.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = \"binary_crossentropy\"\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.1)\n",
    "metrics=[\"accuracy\"]\n",
    "model_3D_col.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_3D_col.fit(vid_arr_col, \n",
    "                           y[:vid_arr_col.shape[0]],\n",
    "                           epochs=10, \n",
    "                           batch_size=10, \n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "metrics=[\"accuracy\"]\n",
    "model_3D_col.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history_test.params)\n",
    "print(history_test.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history_test.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history_test.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
